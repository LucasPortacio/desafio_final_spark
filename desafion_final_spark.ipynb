{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "        .appName(\"desafio_final\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"F:/Documentos/0.XP EDUCACAO/Módulo 2 - Bootcamp cientista de Dados/00.Desafio final/stroke_data.csv\", sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67135\n"
     ]
    }
   ],
   "source": [
    "#Quantos registros existem no arquivo?\n",
    "\n",
    "print(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantas colunas existem no arquivo? Quantas são numéricas? Ao ler o arquivo com spark.read.csv, \n",
    "# habilite inferSchema=True. Use a função printSchema() da API de Dataframes.\n",
    "\n",
    "num_columns = len(data.columns)\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|stroke|count(stroke)|\n",
      "+------+-------------+\n",
      "|     1|        40287|\n",
      "|     0|        26848|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No conjunto de dados, quantos pacientes sofreram e não sofreram derrame (stroke), respectivamente?\n",
    "\n",
    "Stroke = data.groupBy(\"stroke\").agg({\"stroke\": \"count\"})\n",
    "Stroke.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|    work_type|count(1)|\n",
      "+-------------+--------+\n",
      "| Never_worked|      85|\n",
      "|Self-employed|   10807|\n",
      "|      Private|   23711|\n",
      "|     children|     520|\n",
      "|     Govt_job|    5164|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A partir do dataframe, crie uma tabela temporária usando df.createOrReplaceTempView('table') e \n",
    "# a seguir use spark.sql para escrever uma consulta SQL que obtenha quantos pacientes tiveram derrame por \n",
    "# tipo de trabalho (work_type). Quantos pacientes sofreram derrame e trabalhavam respectivamente, no setor privado, \n",
    "# de forma independente, no governo e quantas são crianças?\n",
    "\n",
    "data.createOrReplaceTempView('table')\n",
    "\n",
    "spark.sql(\"select work_type,count(*) from table where stroke = 1 group by work_type\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|gender|count(1)|\n",
      "+------+--------+\n",
      "|Female|   39530|\n",
      "| Other|      11|\n",
      "|  Male|   27594|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Escreva uma consulta com spark.sql para determinar a proporção, por gênero, de \n",
    "# participantes do estudo. A maioria dos participantes é:\n",
    "\n",
    "spark.sql(\"select gender,count(*) from table group by gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------------+\n",
      "|stroke|Count|                 %|\n",
      "+------+-----+------------------+\n",
      "|     1| 8817| 80.03086139602432|\n",
      "|     0| 2200|19.969138603975676|\n",
      "+------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Escreva uma consulta com spark.sql para determinar quem tem mais probabilidade de sofrer derrame: \n",
    "# hipertensos ou não-hipertensos. Você pode escrever uma consulta para cada grupo. \n",
    "# A partir das probabilidades que você obteve, você conclui que:\n",
    "\n",
    "# hipertensos\n",
    "\n",
    "# filtrando hipertensos\n",
    "data_hyper = data.filter(col(\"hypertension\") == 1)\n",
    "# contando hipertensos\n",
    "count_hyper = data.filter(col(\"hypertension\") == 1).count()\n",
    "\n",
    "\n",
    "hyper = data_hyper.groupBy(\"stroke\").agg(count(\"*\").alias(\"Count\"))\n",
    "\n",
    "hyper_percent = hyper.withColumn(\"%\", col(\"Count\")/ count_hyper * 100 )\n",
    "\n",
    "hyper_percent.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------------+\n",
      "|stroke|Count|                %|\n",
      "+------+-----+-----------------+\n",
      "|     1|31470|56.07826365871913|\n",
      "|     0|24648|43.92173634128087|\n",
      "+------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# não hipertensos\n",
    "\n",
    "# filtrando não hipertensos\n",
    "data_nhyper = data.filter(col(\"hypertension\") == 0)\n",
    "# contando hipertensos\n",
    "count_nhyper = data.filter(col(\"hypertension\") == 0).count()\n",
    "\n",
    "\n",
    "hyper = data_nhyper.groupBy(\"stroke\").agg(count(\"*\").alias(\"Count\"))\n",
    "\n",
    "hyper_percent = hyper.withColumn(\"%\", col(\"Count\")/ count_nhyper * 100 )\n",
    "\n",
    "hyper_percent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "| age|count(1)|\n",
      "+----+--------+\n",
      "|79.0|    2916|\n",
      "|78.0|    2279|\n",
      "|80.0|    1858|\n",
      "|81.0|    1738|\n",
      "|82.0|    1427|\n",
      "|77.0|     994|\n",
      "|74.0|     987|\n",
      "|63.0|     942|\n",
      "|76.0|     892|\n",
      "|70.0|     881|\n",
      "|66.0|     848|\n",
      "|75.0|     809|\n",
      "|67.0|     801|\n",
      "|57.0|     775|\n",
      "|73.0|     759|\n",
      "|65.0|     716|\n",
      "|72.0|     709|\n",
      "|68.0|     688|\n",
      "|69.0|     677|\n",
      "|71.0|     667|\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Escreva uma consulta com spark.sql que determine o número de pessoas que sofreram derrame por idade. \n",
    "# Com qual idade o maior número de pessoas do conjunto de dados sofreu derrame?\n",
    "\n",
    "spark.sql(\"select age,count(*) from table where stroke = 1 group by age order by count(*) desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28938\n"
     ]
    }
   ],
   "source": [
    "# Usando a API de dataframes, determine quantas pessoas sofreram derrames após os 50 anos.\n",
    "\n",
    "# filtrando pessoas com derrames e após 50 anos\n",
    "age_50 = data.filter((col(\"age\") > 50) & (col(\"stroke\") == 1))\n",
    "\n",
    "cont_50 = age_50.count()\n",
    "\n",
    "print(cont_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|stroke|             Count|\n",
      "+------+------------------+\n",
      "|     1|119.95307046938272|\n",
      "|     0|103.60273130214506|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usando spark.sql, determine qual o nível médio de glicose para pessoas que, \n",
    "# respectivamente, sofreram e não sofreram derrame.\n",
    "\n",
    "\n",
    "glicose = data.groupBy(\"stroke\").agg(avg(\"avg_glucose_level\").alias(\"Count\"))\n",
    "\n",
    "glicose.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|stroke|          avg(bmi)|\n",
      "+------+------------------+\n",
      "|     1|29.942490629729495|\n",
      "|     0|27.989678933253657|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Qual é o BMI (IMC = índice de massa corpórea) médio de quem sofreu e não sofreu derrame?\n",
    "\n",
    "imc = data.groupBy(\"stroke\").agg(avg(\"bmi\"))\n",
    "imc.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------- Estudar para melhor entendimento ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área sob a Curva (Area Under ROC Curve): 0.6245344446021796\n",
      "Árvore de Decisão:\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_be047e84d256, depth=5, numNodes=39, numClasses=2, numFeatures=5\n",
      "  If (feature 0 <= 55.5)\n",
      "   If (feature 0 <= 13.5)\n",
      "    If (feature 0 <= 7.5)\n",
      "     Predict: 0.0\n",
      "    Else (feature 0 > 7.5)\n",
      "     If (feature 1 <= 19.95)\n",
      "      If (feature 2 <= 0.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 1 > 19.95)\n",
      "      Predict: 0.0\n",
      "   Else (feature 0 > 13.5)\n",
      "    If (feature 2 <= 0.5)\n",
      "     If (feature 0 <= 33.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 > 33.5)\n",
      "      If (feature 1 <= 31.25)\n",
      "       Predict: 1.0\n",
      "      Else (feature 1 > 31.25)\n",
      "       Predict: 0.0\n",
      "    Else (feature 2 > 0.5)\n",
      "     If (feature 0 <= 46.5)\n",
      "      If (feature 1 <= 35.349999999999994)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 35.349999999999994)\n",
      "       Predict: 1.0\n",
      "     Else (feature 0 > 46.5)\n",
      "      Predict: 1.0\n",
      "  Else (feature 0 > 55.5)\n",
      "   If (feature 0 <= 72.5)\n",
      "    If (feature 4 <= 132.555)\n",
      "     If (feature 2 <= 0.5)\n",
      "      If (feature 1 <= 21.05)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 21.05)\n",
      "       Predict: 1.0\n",
      "     Else (feature 2 > 0.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 4 > 132.555)\n",
      "     Predict: 1.0\n",
      "   Else (feature 0 > 72.5)\n",
      "    If (feature 0 <= 77.5)\n",
      "     If (feature 1 <= 19.95)\n",
      "      If (feature 4 <= 61.655)\n",
      "       Predict: 1.0\n",
      "      Else (feature 4 > 61.655)\n",
      "       Predict: 0.0\n",
      "     Else (feature 1 > 19.95)\n",
      "      Predict: 1.0\n",
      "    Else (feature 0 > 77.5)\n",
      "     If (feature 2 <= 0.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 2 > 0.5)\n",
      "      If (feature 1 <= 18.35)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 18.35)\n",
      "       Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crie um modelo de árvore de decisão que prevê a chance de derrame (stroke) a partir das variáveis contínuas/categóricas: \n",
    "# idade, BMI, hipertensão, doença do coração, nível médio de glicose. Use o conteúdo da segunda aula interativa para criar \n",
    "# e avaliar o modelo.\n",
    "\n",
    "# Prepare as features usando VectorAssembler\n",
    "feature_columns = [\"age\", \"bmi\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_assembled = assembler.transform(data)\n",
    "\n",
    "# Divida o conjunto de dados em treino e teste\n",
    "(training_data, test_data) = df_assembled.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Crie o modelo de árvore de decisão\n",
    "dt = DecisionTreeClassifier(labelCol=\"stroke\", featuresCol=\"features\")\n",
    "model = dt.fit(training_data)\n",
    "\n",
    "# Faça previsões no conjunto de teste\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Avalie o desempenho do modelo usando BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"stroke\", rawPredictionCol=\"rawPrediction\")\n",
    "area_under_curve = evaluator.evaluate(predictions)\n",
    "\n",
    "# Exiba a Área sob a Curva (Area Under ROC Curve)\n",
    "print(f\"Área sob a Curva (Area Under ROC Curve): {area_under_curve}\")\n",
    "\n",
    "# Exiba a árvore de decisão\n",
    "print(\"Árvore de Decisão:\")\n",
    "print(model.toDebugString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Modelo: 0.6901492537313433\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Avalie o desempenho do modelo usando MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"stroke\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Calcule a acurácia\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# Exiba a acurácia\n",
    "print(f\"Acurácia do Modelo: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Modelo com Variáveis Categóricas: 0.8373880597014925\n"
     ]
    }
   ],
   "source": [
    "# Adicione ao modelo as variáveis categóricas: gênero e status de fumante. \n",
    "# Use o conteúdo da aula interativa para lidar com as variáveis categóricas.  \n",
    "# A acurácia (qualidade) do modelo aumentou para:\n",
    "\n",
    "\n",
    "# Indexação das variáveis categóricas\n",
    "gender_indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_index\")\n",
    "smoking_status_indexer = StringIndexer(inputCol=\"smoking_status\", outputCol=\"smoking_status_index\")\n",
    "\n",
    "# Codificação OneHot das variáveis indexadas\n",
    "gender_encoder = OneHotEncoder(inputCol=\"gender_index\", outputCol=\"gender_encoded\")\n",
    "smoking_status_encoder = OneHotEncoder(inputCol=\"smoking_status_index\", outputCol=\"smoking_status_encoded\")\n",
    "\n",
    "# Prepare as features usando VectorAssembler\n",
    "feature_columns = [\n",
    "    \"age\", \"bmi\", \"hypertension\", \"heart_disease\", \"avg_glucose_level\",\n",
    "    \"gender_encoded\", \"smoking_status_encoded\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Crie o modelo de árvore de decisão\n",
    "dt = DecisionTreeClassifier(labelCol=\"stroke\", featuresCol=\"features\")\n",
    "\n",
    "# Construa o pipeline\n",
    "pipeline = Pipeline(stages=[gender_indexer, smoking_status_indexer, gender_encoder, smoking_status_encoder, assembler, dt])\n",
    "\n",
    "# Divida o conjunto de dados em treino e teste\n",
    "(training_data, test_data) = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Treine o modelo\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Faça previsões no conjunto de teste\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Avalie o desempenho do modelo usando MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"stroke\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Calcule a acurácia\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# Exiba a acurácia\n",
    "print(f\"Acurácia do Modelo com Variáveis Categóricas: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importância das Variáveis:\n",
      "age: 0.16916221419073177\n",
      "avg_glucose_level: 0.00841995578767354\n",
      "gender_encoded: 0.0007725059616589108\n",
      "bmi: 0.0007348283708603001\n",
      "hypertension: 0.0\n",
      "heart_disease: 0.0\n",
      "smoking_status_encoded: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Qual dessas variáveis é mais importante no modelo de árvore de decisão que você construiu?\n",
    "\n",
    "# Treine o modelo\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Acesse as importâncias das variáveis\n",
    "importances = model.stages[-1].featureImportances.toArray()\n",
    "\n",
    "# Crie um dicionário associando o nome da variável à sua importância\n",
    "feature_importance_dict = dict(zip(feature_columns, importances))\n",
    "\n",
    "# Exiba a importância das variáveis\n",
    "print(\"Importância das Variáveis:\")\n",
    "for feature, importance in sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidade da Árvore de Decisão: 5\n"
     ]
    }
   ],
   "source": [
    "# Adicione ao modelo as variáveis categóricas: gênero e status de fumante. \n",
    "# Use o conteúdo da aula interativa para lidar com as variáveis categóricas. \n",
    "# Qual a profundidade da árvore de decisão? \n",
    "\n",
    "\n",
    "# Treine o modelo\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Acesse a profundidade da árvore\n",
    "tree_depth = model.stages[-1].getOrDefault(\"maxDepth\")\n",
    "\n",
    "# Exiba a profundidade da árvore\n",
    "print(f\"Profundidade da Árvore de Decisão: {tree_depth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Nós na Árvore de Decisão: 25\n"
     ]
    }
   ],
   "source": [
    "# Quantos nodos a árvore de decisão possui?\n",
    "\n",
    "# Treine o modelo\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Acesse o número de nós na árvore\n",
    "num_nodes = model.stages[-1].numNodes\n",
    "\n",
    "# Exiba o número de nós na árvore\n",
    "print(f\"Número de Nós na Árvore de Decisão: {num_nodes}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "713144d2bbbede84a1da11c85bed8fc4e42675ca1a53431544ec4ad4bc9f036f"
  },
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
